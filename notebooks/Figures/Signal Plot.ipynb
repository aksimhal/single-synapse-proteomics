{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b3498-27c5-41db-a9ca-4949b2e3cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import sys\n",
    "from scipy.signal import savgol_filter\n",
    "import scipy.stats\n",
    "from scipy.stats import tukey_hsd\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12b09b-8152-4d46-91f5-341f9daa35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab234250-2289-4ff5-80b4-8d2013531dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae81105-41a3-4049-a9c4-9802456eab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.seterr(divide='ignore')\n",
    "\n",
    "# Set figure export properties\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Arial\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "\n",
    "# Set which plots to generate\n",
    "generate_level_plots = True\n",
    "generate_size_hist_plots = True\n",
    "generate_GABA_content_plots = True\n",
    "generate_scatter_plots = True\n",
    "generate_umap = True\n",
    "\n",
    "# Save plots as PDFs. Alternatively leave them open for display\n",
    "save_plots = False\n",
    "\n",
    "# Filenames to grab data\n",
    "fdir = '' #r'Z:\\Data\\AT_Image_Data\\KDMSYN201228_F002_IF'\n",
    "fname = 'KDMSYN201228_F002_IF_exc_intens_dil_0.csv'\n",
    "\n",
    "cmap = plt.get_cmap('cool') # Colormap for scatter plots\n",
    "num_size_bins = 7   # Number of bins to split into for size dependence plots\n",
    "num_clusts = 4 # Number of clusters to cut (selected from Silhouette analysis)\n",
    "sum_or_avg = 'avg' # Use sum or average intensity values for synapses\n",
    "\n",
    "# Set exclustion criteria for outliers based on size or intensities\n",
    "excl_syn_size = 250 # Exclude synapses that are absurdly large assuming excessive merging\n",
    "q1_trim = 0.05\n",
    "q3_trim = 0.95\n",
    "quartile_mult = 1.5\n",
    "\n",
    "# Set parameters for scatter plots\n",
    "num_hist_bins = 100 # Number of histogram bins for scatter plots\n",
    "smooth_len = 10     # Smoothing of lines for scatter plots\n",
    "alpha_val = 0.5 # Transparency value for Scatter Plots\n",
    "size_scale = 5 # Size scaling of points for Scatter Plots\n",
    "gaba_cutoff = 0.98  # Cutoff to identify synapses onto GABAergic targets\n",
    "\n",
    "# Key for resetting cluster numbers (colors) to match conjugate dataset\n",
    "clust_conj = [0,1,2,3]\n",
    "clust_if   = [3,2,1,0]\n",
    "\n",
    "\n",
    "use_stains = ['num_pixels', \n",
    "             'PSD95_' + sum_or_avg,\n",
    "             'Synapsin12_' + sum_or_avg,\n",
    "             'GluA1_' + sum_or_avg, \n",
    "             'GluA2_' + sum_or_avg, \n",
    "             'GluA3_' + sum_or_avg, \n",
    "             'GluA4_' + sum_or_avg, \n",
    "             'GluN1_' + sum_or_avg, \n",
    "             'GluN2B_' + sum_or_avg, \n",
    "             'GABA_dil2_' + sum_or_avg, \n",
    "             'Gephyrin_' + sum_or_avg]\n",
    "\n",
    "# List of channels to plot against one another for scatter plots\n",
    "plt_list = [['GluA2_' + sum_or_avg, 'GluA1_' + sum_or_avg],\n",
    "            ['GluA2_' + sum_or_avg, 'GluA3_' + sum_or_avg],\n",
    "            ['GluA2_' + sum_or_avg, 'GluA4_' + sum_or_avg],\n",
    "            ['GluA1_' + sum_or_avg, 'GluA3_' + sum_or_avg],\n",
    "            ['GluA2_' + sum_or_avg, 'GluN1_' + sum_or_avg],\n",
    "            ['GluN1_' + sum_or_avg, 'GluN2B_' + sum_or_avg],\n",
    "            ['GluA2_' + sum_or_avg, 'GluN2B_' + sum_or_avg]]\n",
    "\n",
    "# Plot each of these channel intensities against: (1) synapse size distribution; (2) top 10% GABA\n",
    "size_hist_plots = ['GluA1_' + sum_or_avg, 'GluA2_'+ sum_or_avg, 'GluA3_'+ sum_or_avg, 'GluA4_'+ sum_or_avg, \n",
    "                   'num_pixels', 'GluN1_'+ sum_or_avg, 'GluN2B_'+ sum_or_avg, \n",
    "                   'PSD95_'+ sum_or_avg, 'GABA_dil2_'+ sum_or_avg, 'anratio_' + sum_or_avg]\n",
    "\n",
    "# List of channels to include in UMAP plot\n",
    "umap_list = ['num_pixels',\n",
    "             'PSD95_' + sum_or_avg, \n",
    "             'GluA1_' + sum_or_avg, \n",
    "             'GluA2_' + sum_or_avg, \n",
    "             'GluA3_' + sum_or_avg, \n",
    "             'GluA4_' + sum_or_avg, \n",
    "             'GluN1_' + sum_or_avg, \n",
    "             'GluN2B_' + sum_or_avg]\n",
    "\n",
    "# Channels to group together for AMPA and NMDA combined\n",
    "ampa_comb_list = ['GluA1','GluA2','GluA3','GluA4']\n",
    "nmda_comb_list = ['GluN1','GluN2B']\n",
    "scatt_size_label = 'num_pixels'\n",
    "num_pix_label = 'num_pixels'\n",
    "gaba_cut_label = 'GABA_dil2_'+ sum_or_avg\n",
    "\n",
    "# Read in CSV values\n",
    "csv_vals = pd.read_csv(fdir + fname)\n",
    "csv_vals = csv_vals[csv_vals[num_pix_label] <= excl_syn_size]\n",
    "\n",
    "# Grab the appropriate list of shuffled data channels\n",
    "shuffle_list = []\n",
    "for stain_ct, stain_val in enumerate(use_stains):\n",
    "    if '_avg' in stain_val:\n",
    "        shuffle_list.append(stain_val.replace('avg','shuffleavg'))\n",
    "    if '_sum' in stain_val:\n",
    "        shuffle_list.append(stain_val.replace('sum','shufflesum'))\n",
    "use_stains = use_stains + shuffle_list    \n",
    "\n",
    "# Function for trimming outliers\n",
    "def trim_quartile(x_vals, q1_trim, q3_trim, quartile_mult):\n",
    "    x_vals = pd.DataFrame(x_vals).copy()\n",
    "    q1 = x_vals.quantile(q1_trim)\n",
    "    q3 = x_vals.quantile(q3_trim)\n",
    "    iqr = q3 - q1\n",
    "    lb = q1 - (quartile_mult * iqr)\n",
    "    ub = q3 + (quartile_mult * iqr)\n",
    "    bool_vals = np.array((x_vals >= lb) & (x_vals <= ub))[:,0].copy()\n",
    "    x_vals = x_vals[bool_vals].copy()\n",
    "    return x_vals, bool_vals\n",
    "\n",
    "###############################################################################\n",
    "# Combine values for AMPA and NMDA receptors to calculate AMPA/NMDA ratio     #\n",
    "###############################################################################\n",
    "\n",
    "# Initialize arrays for combined AMPA and NMDA ratios\n",
    "csv_vals['ampa_comb_avg'] = np.zeros(len(csv_vals))\n",
    "csv_vals['ampa_comb_sum'] = np.zeros(len(csv_vals))\n",
    "csv_vals['ampa_comb_shuffleavg'] = np.zeros(len(csv_vals))\n",
    "csv_vals['ampa_comb_shufflesum'] = np.zeros(len(csv_vals))\n",
    "csv_vals['nmda_comb_avg'] = np.zeros(len(csv_vals))\n",
    "csv_vals['nmda_comb_sum'] = np.zeros(len(csv_vals))\n",
    "csv_vals['nmda_comb_shuffleavg'] = np.zeros(len(csv_vals))\n",
    "csv_vals['nmda_comb_shufflesum'] = np.zeros(len(csv_vals))\n",
    "# Calculate combined AMPA and NMDA ratios\n",
    "for this_ct,this_chan in enumerate(ampa_comb_list):\n",
    "    csv_vals['ampa_comb_avg'] = csv_vals['ampa_comb_avg'] + (csv_vals[this_chan + '_avg'] / len(ampa_comb_list))\n",
    "    csv_vals['ampa_comb_sum'] = csv_vals['ampa_comb_sum']  + (csv_vals[this_chan + '_sum'] / len(ampa_comb_list))\n",
    "    csv_vals['ampa_comb_shuffleavg'] = csv_vals['ampa_comb_shuffleavg'] + (csv_vals[this_chan + '_shuffleavg'] / len(ampa_comb_list))\n",
    "    csv_vals['ampa_comb_shufflesum'] = csv_vals['ampa_comb_shufflesum'] + (csv_vals[this_chan + '_shufflesum'] / len(ampa_comb_list))\n",
    "for this_ct,this_chan in enumerate(nmda_comb_list):\n",
    "    csv_vals['nmda_comb_avg'] = csv_vals['nmda_comb_avg'] + (csv_vals[this_chan + '_avg'] / len(nmda_comb_list))\n",
    "    csv_vals['nmda_comb_sum'] = csv_vals['nmda_comb_sum']  + (csv_vals[this_chan + '_sum'] / len(nmda_comb_list))\n",
    "    csv_vals['nmda_comb_shuffleavg'] = csv_vals['nmda_comb_shuffleavg'] + (csv_vals[this_chan + '_shuffleavg'] / len(nmda_comb_list))\n",
    "    csv_vals['nmda_comb_shufflesum'] = csv_vals['nmda_comb_shufflesum'] + (csv_vals[this_chan + '_shufflesum'] / len(nmda_comb_list))\n",
    "# Story combined AMPA and NMDA ratios in the larger dataset\n",
    "csv_vals['anratio_avg'] = csv_vals['ampa_comb_avg'] / csv_vals['nmda_comb_avg']\n",
    "csv_vals['anratio_sum'] = csv_vals['ampa_comb_sum'] / csv_vals['nmda_comb_sum']\n",
    "csv_vals['anratio_shuffleavg'] = csv_vals['ampa_comb_shuffleavg'] / csv_vals['nmda_comb_shuffleavg']\n",
    "csv_vals['anratio_shufflesum'] = csv_vals['ampa_comb_shufflesum'] / csv_vals['nmda_comb_shufflesum']\n",
    "csv_vals[np.isnan(csv_vals)] = 0\n",
    "\n",
    "# Drop all columns not in use\n",
    "csv_vals_trunc = csv_vals.copy()[use_stains]\n",
    "\n",
    "###############################################################################\n",
    "#      Plot the average values for each channel in box (or violin) plot       #\n",
    "###############################################################################\n",
    "\n",
    "# Create a DataFrame for plotting average values\n",
    "syn_avg_df = pd.DataFrame()\n",
    "stain_list = [[] for _ in range(len(csv_vals_trunc))]\n",
    "for stain_ct, stain_val in enumerate(csv_vals_trunc.columns):\n",
    "    if ('_avg' in stain_val) or ('_sum' in stain_val):\n",
    "        stain_val_shuffle = stain_val.replace('_avg','_shuffleavg').replace('_sum','_shufflesum')\n",
    "        stain_val_norm = stain_val.replace('_avg','_normavg').replace('_sum','_normsum')\n",
    "        for syn_ct, syn_val in enumerate(stain_list):\n",
    "            stain_list[syn_ct] = stain_val\n",
    "        syn_avg_df = pd.concat([syn_avg_df,pd.DataFrame({'Stain':stain_list,\n",
    "                                                         'Fluor':csv_vals_trunc[stain_val],\n",
    "                                                         'Shuff':csv_vals_trunc[stain_val_shuffle],\n",
    "                                                         'Norm':csv_vals_trunc[stain_val] - np.mean(csv_vals_trunc[stain_val_shuffle])})],\n",
    "                               ignore_index=True)\n",
    "\n",
    "if generate_level_plots:\n",
    "    # Box plot average intensities\n",
    "    plt_fig = plt.figure(figsize=[12,6])\n",
    "    bar_ax = plt_fig.add_subplot(121)\n",
    "    box_ax = plt_fig.add_subplot(122)\n",
    "    plt_fig_nsub = plt.figure(figsize=[12,6])\n",
    "    bar_ax_nsub = plt_fig_nsub.add_subplot(121)\n",
    "    box_ax_nsub = plt_fig_nsub.add_subplot(122)\n",
    "    box_df      = pd.DataFrame()\n",
    "    box_df_trim = pd.DataFrame()\n",
    "    sub_vals      = np.zeros(len(np.unique(syn_avg_df['Stain'])))\n",
    "    sub_vals_trim = np.zeros(len(np.unique(syn_avg_df['Stain'])))\n",
    "    for stain_ct, stain_val in enumerate(np.unique(syn_avg_df['Stain'])):\n",
    "        # Build list for y-axis values and labels\n",
    "        y_vals = syn_avg_df['Fluor'][syn_avg_df['Stain']==stain_val]\n",
    "        if len(y_vals) > 0:\n",
    "            # Identify shuffled intensities\n",
    "            y_vals_shuff = syn_avg_df['Shuff'][syn_avg_df['Stain']==stain_val]\n",
    "            # Trim outliers\n",
    "            y_vals_trim,       trim_bool       = trim_quartile(y_vals,       q1_trim, q3_trim, quartile_mult)\n",
    "            y_vals_shuff_trim, shuff_trim_bool = trim_quartile(y_vals_shuff, q1_trim, q3_trim, quartile_mult)\n",
    "            \n",
    "            # Subtract background (shuffled) intensities\n",
    "            sub_vals[stain_ct]      = np.mean(y_vals_shuff)\n",
    "            sub_vals_trim[stain_ct] = np.mean(y_vals_shuff_trim)\n",
    "            y_vals_sub      = y_vals      - sub_vals[stain_ct]\n",
    "            y_vals_sub_trim = y_vals_trim - sub_vals_trim[stain_ct]\n",
    "            \n",
    "            # Build list for y-axis values and labels\n",
    "            y_labels      = []\n",
    "            y_labels_trim = []\n",
    "            for y_ct, y_val in enumerate(y_vals):\n",
    "                y_labels.append(stain_val)\n",
    "            for y_ct, y_val in enumerate(y_vals[trim_bool]):\n",
    "                y_labels_trim.append(stain_val)\n",
    "            # Append values to DataFrame\n",
    "            box_df = pd.concat([box_df, pd.DataFrame(data={'Labels':y_labels,\n",
    "                                                           'Fluor':y_vals,\n",
    "                                                           'Shuff':y_vals_shuff,\n",
    "                                                           'Fluor_sub':y_vals_sub})],ignore_index=True)\n",
    "            box_df_trim = pd.concat([box_df_trim, pd.DataFrame(data={'Labels':    y_labels_trim,\n",
    "                                                                     'Fluor':     y_vals_trim.squeeze(),\n",
    "                                                                     'Shuff':     y_vals[trim_bool].squeeze(),\n",
    "                                                                     'Fluor_sub': y_vals_sub_trim.squeeze()})],\n",
    "                                    ignore_index=True)\n",
    "            \n",
    "            # Plot with errorbars\n",
    "            bar_ax.bar(stain_ct, np.mean(y_vals_sub_trim,axis=0),edgecolor='k',facecolor='none')\n",
    "            bar_ax.errorbar(stain_ct, np.mean(y_vals_sub_trim,axis=0),scipy.stats.sem(y_vals_sub_trim),\n",
    "                            marker='.',markersize=10,markerfacecolor='none',markeredgecolor='none',\n",
    "                            linestyle='none',color='k')\n",
    "            \n",
    "            bar_ax_nsub.bar(stain_ct, np.mean(y_vals_trim,axis=0),edgecolor='k',facecolor='none')\n",
    "            bar_ax_nsub.errorbar(stain_ct, np.mean(y_vals_trim,axis=0),scipy.stats.sem(y_vals_trim),\n",
    "                                 marker='.',markersize=10,markerfacecolor='none',markeredgecolor='none',\n",
    "                                 linestyle='none',color='k')\n",
    "    \n",
    "    # Generate boxplot\n",
    "    sns.stripplot(data=box_df_trim,x='Labels',y='Fluor_sub',color='k',edgecolor='none',size=.5,ax=box_ax)\n",
    "    sns.boxplot(data=box_df_trim,x='Labels',y='Fluor_sub',fliersize=0,whis=0,ax=box_ax,color='w',showmeans=True,\n",
    "                meanprops={'marker':'+','markerfacecolor':'w','markeredgecolor':'r','markersize':20})\n",
    "    \n",
    "    \n",
    "    sns.stripplot(data=box_df_trim,x='Labels',y='Fluor',color='k',edgecolor='none',size=.5,ax=box_ax_nsub)\n",
    "    sns.boxplot(data=box_df_trim,x='Labels',y='Fluor',fliersize=0,whis=0,ax=box_ax_nsub,color='w',showmeans=True,\n",
    "                meanprops={'marker':'+','markerfacecolor':'w','markeredgecolor':'r','markersize':20})\n",
    "    \n",
    "    # Set axis properties\n",
    "    bar_ax.set(ylabel='Fluorescence (BL Sub)',xlabel='Stain',xticks=np.arange(0,len(np.unique(syn_avg_df['Stain']))),\n",
    "               xticklabels=np.unique(syn_avg_df['Stain']),title='Baseline Subtracted')\n",
    "    bar_ax.set_xticklabels(bar_ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    box_ax.set(ylabel='Fluorescence (BL Sub)',yscale='linear',title='Baseline Subtracted',\n",
    "               xlabel='Stain',xticks=np.arange(0,len(np.unique(syn_avg_df['Stain']))),\n",
    "               xticklabels=np.unique(syn_avg_df['Stain']))\n",
    "    box_ax.set_xticklabels(box_ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    bar_ax_nsub.set(ylabel='Fluorescence',xlabel='Stain',xticks=np.arange(0,len(np.unique(syn_avg_df['Stain']))),\n",
    "                    xticklabels=np.unique(syn_avg_df['Stain']),title='Raw Values')\n",
    "    bar_ax_nsub.set_xticklabels(bar_ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    box_ax_nsub.set(ylabel='Fluorescence',yscale='linear',title='Raw Values',\n",
    "               xlabel='Stain',xticks=np.arange(0,len(np.unique(syn_avg_df['Stain']))),\n",
    "               xticklabels=np.unique(syn_avg_df['Stain']))\n",
    "    box_ax_nsub.set_xticklabels(box_ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt_fig_nsub.savefig(fdir + '/if_label_nsublevels.pdf')\n",
    "        plt.close(plt_fig_nsub)\n",
    "        plt_fig.savefig(fdir + '/if_label_levels.pdf')\n",
    "        plt.close(plt_fig)\n",
    "\n",
    "###############################################################################\n",
    "#      Plot the values binned by synapse size                                 #\n",
    "###############################################################################\n",
    "\n",
    "if generate_size_hist_plots:\n",
    "    # Initialize histogram bins\n",
    "    x_vals = np.log(np.array(csv_vals[num_pix_label]))\n",
    "    hist_bins = np.linspace(np.min(x_vals),np.max(x_vals),num_size_bins + 1)\n",
    "        \n",
    "    # Generate figure\n",
    "    bar_fig = plt.figure(figsize=[19,8])\n",
    "    \n",
    "    # Cycle through each plot to generate\n",
    "    for plt_ct, plt_label in enumerate(size_hist_plots):\n",
    "        # Select axes in each plot\n",
    "        bar_ax = bar_fig.add_subplot(2,5,plt_ct + 1)\n",
    "        \n",
    "        # Grab values for this channel and remove outliers\n",
    "        y_vals = np.array(csv_vals[plt_label])\n",
    "        y_vals_trim, trim_bool = trim_quartile(y_vals, q1_trim, q3_trim, quartile_mult)\n",
    "        x_vals_trim = x_vals[trim_bool]\n",
    "        \n",
    "        # Initialize bin values\n",
    "        bin_nums = np.ones(len(x_vals_trim)) * -1\n",
    "        num_syn = np.zeros(len(hist_bins) - 1)\n",
    "        bin_labels = []\n",
    "        \n",
    "        # Calculate histogram values\n",
    "        for bin_ct, this_bin in enumerate(hist_bins[0:-1]):\n",
    "            # Identify synapses falling within this histogram bin\n",
    "            these_syn = (x_vals_trim >= hist_bins[bin_ct]) & (x_vals_trim < hist_bins[bin_ct + 1])\n",
    "            num_syn[bin_ct] = np.sum(these_syn)\n",
    "            bin_nums[these_syn] = bin_ct\n",
    "            bin_labels.append('{:.0f}'.format(np.exp(hist_bins[bin_ct])) + ' - ' + '{:.0f}'.format(np.exp(hist_bins[bin_ct + 1])))\n",
    "            \n",
    "            # Build list of bin labels\n",
    "            bar_ax.bar(bin_ct, np.mean(y_vals_trim[bin_nums==bin_ct],axis=0),edgecolor='k',facecolor='none')\n",
    "            bar_ax.errorbar(bin_ct, np.mean(y_vals_trim[bin_nums==bin_ct],axis=0), \n",
    "                            scipy.stats.sem(y_vals_trim[bin_nums==bin_ct]),\n",
    "                            marker='.',markersize=10,markerfacecolor='none',markeredgecolor='none',\n",
    "                            linestyle='none',color='k')\n",
    "        \n",
    "        bar_ax.set(title=plt_label,xlabel='Synapse Size',ylabel=plt_label,\n",
    "                   xticks=np.arange(0,len(bin_labels)),xticklabels=bin_labels)\n",
    "        bar_ax.set_xticklabels(bar_ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Generate figure for average intensity correlations\n",
    "    ecdf_fig = plt.figure(figsize=[19,8])\n",
    "    \n",
    "    # Grab values for histogram\n",
    "    x_vals = np.log(np.array(csv_vals[num_pix_label]))\n",
    "    \n",
    "    # Set up histogram bins\n",
    "    hist_bins = np.linspace(np.min(x_vals), np.max(x_vals), num_size_bins)\n",
    "    \n",
    "    # Pick a color scheme for plotting\n",
    "    color_vals = np.linspace(0,1,num_size_bins)\n",
    "    color_data = cmap(color_vals)\n",
    "    \n",
    "    # Initialize DataFrame for cumulative distributions\n",
    "    ecdf_df = pd.DataFrame()\n",
    "    \n",
    "    # Cycle through each plot to generate\n",
    "    for plt_ct, plt_label in enumerate(size_hist_plots):\n",
    "        # Generate axis\n",
    "        ecdf_ax = ecdf_fig.add_subplot(2,5,plt_ct + 1)\n",
    "        \n",
    "        # Convert values to an array\n",
    "        y_vals = np.array(csv_vals[plt_label])\n",
    "        \n",
    "        # Trim outliers\n",
    "        y_vals_trim, trim_bool = trim_quartile(y_vals, q1_trim, q3_trim, quartile_mult)\n",
    "        x_vals_trim = x_vals[trim_bool]\n",
    "        \n",
    "        # Initialize arrays\n",
    "        bin_nums = np.ones(len(x_vals_trim)) * -1\n",
    "        num_syn = np.zeros(len(hist_bins) - 1)\n",
    "        bin_labels = []\n",
    "        \n",
    "        # Cycle through histogram bins to identify & count synapses\n",
    "        for bin_ct, this_bin in enumerate(hist_bins[0:-1]):\n",
    "            # Fins synapses belonging to this bin\n",
    "            these_syn = (x_vals_trim >= hist_bins[bin_ct]) & (x_vals_trim < hist_bins[bin_ct + 1])\n",
    "            num_syn[bin_ct] = np.sum(these_syn) # Store in array\n",
    "            bin_nums[these_syn] = bin_ct\n",
    "            bin_labels.append('{:.0f}'.format(np.exp(hist_bins[bin_ct])) + ' - ' + '{:.0f}'.format(np.exp(hist_bins[bin_ct + 1])))\n",
    "            \n",
    "            # Generate plot\n",
    "            sns.ecdfplot(data=np.array(y_vals_trim[bin_nums == bin_ct]).ravel(),color=color_data[bin_ct,0:3],\n",
    "                         label='Bin ' + str(bin_ct),ax=ecdf_ax)\n",
    "\n",
    "        ecdf_ax.set(title=plt_label,xlabel='Synapse Size',ylabel=plt_label,xscale='log') # Set axis title\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Plot number of synapses per bin\n",
    "    plt_fig = plt.figure()\n",
    "    plt_ax = plt_fig.add_subplot(111)\n",
    "    plt_ax.bar(np.arange(0,len(bin_labels)), num_syn,facecolor='w',edgecolor='k')\n",
    "    plt_ax.set(title='Number of Synapses',xlabel='Synapse size bin',ylabel='Number of Synapses',\n",
    "               xticks=np.arange(0,len(bin_labels)),xticklabels=bin_labels)\n",
    "    plt_ax.set_xticklabels(plt_ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        save_fname = fdir + '/if_synsize_values.pdf'\n",
    "        bar_fig.savefig(save_fname)\n",
    "        plt.close(bar_fig)\n",
    "        save_fname = fdir + '/if_synsize_cdf.pdf'\n",
    "        ecdf_fig.savefig(save_fname)\n",
    "        plt.close(ecdf_fig)\n",
    "        save_fname = fdir + '/if_synsize_numsyns.pdf'\n",
    "        plt_fig.savefig(save_fname)\n",
    "        plt.close(plt_fig)\n",
    "    \n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "#      Plot the values binned by GABA content                                 #\n",
    "###############################################################################\n",
    "\n",
    "if generate_GABA_content_plots:\n",
    "    x_vals = np.array(csv_vals[gaba_cut_label])\n",
    "    x_vals_trim, trim_bool_x = trim_quartile(x_vals, q1_trim, q3_trim, quartile_mult)\n",
    "    gaba_thresh = np.sort(np.array(x_vals_trim[list(x_vals_trim)[0]]))[int(gaba_cutoff * len(x_vals_trim))]\n",
    "    plt_fig = plt.figure(figsize=[18,7])\n",
    "    for plt_ct, plt_label in enumerate(size_hist_plots):\n",
    "        \n",
    "        plt_ax = plt_fig.add_subplot(2,5,plt_ct + 1)\n",
    "        y_vals = csv_vals[plt_label]\n",
    "        y_vals_trim, trim_bool_y = trim_quartile(y_vals, q1_trim, q3_trim, quartile_mult)\n",
    "        y_vals_bot = np.array(y_vals[(x_vals <  gaba_thresh) & trim_bool_x & trim_bool_y])\n",
    "        y_vals_top = np.array(y_vals[(x_vals >= gaba_thresh) & trim_bool_x & trim_bool_y])\n",
    "        \n",
    "        sns.ecdfplot(data=y_vals_bot,ax=plt_ax,color='b',label='Low GABA')\n",
    "        sns.ecdfplot(data=y_vals_top,ax=plt_ax,color='r',label='High GABA')\n",
    "        res = tukey_hsd(y_vals_bot,y_vals_top)\n",
    "        plt_ax.set(xscale='log',title=plt_label + ' -- P=' + '{:.2e}'.format(res.pvalue[0,1]))\n",
    "        plt_ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        save_fname = fdir + '/if_gaba_cut' + str(gaba_cutoff) + '.pdf'\n",
    "        plt_fig.savefig(save_fname)\n",
    "        plt.close(plt_fig)\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#        Plot correlations across channels at single-synapse level            #\n",
    "###############################################################################\n",
    "\n",
    "if generate_scatter_plots:\n",
    "    # Gerate figure for average intensity correlations\n",
    "    color_vals = np.log(csv_vals[scatt_size_label])\n",
    "    size_vals = csv_vals[scatt_size_label]\n",
    "    norm = plt.Normalize(np.min(color_vals), np.max(color_vals))\n",
    "    color_data = cmap(norm(color_vals))\n",
    "    \n",
    "    # Loop through each plot to generate\n",
    "    for plt_ct in range(0,len(plt_list)):\n",
    "        # Create the figure\n",
    "        scat_fig = plt.figure(figsize=[11,8])\n",
    "        gs = GridSpec(5,6,figure=scat_fig)\n",
    "        scat_ax = scat_fig.add_subplot(gs[0:4,0:4])\n",
    "        hist_ax0 = scat_fig.add_subplot(gs[4,0:4])\n",
    "        hist_ax1 = scat_fig.add_subplot(gs[0:4,4])\n",
    "        cax = scat_fig.add_subplot(gs[0:4,5])\n",
    "        \n",
    "        # Calculate values separately for channels \n",
    "        x_vals = np.log(csv_vals[plt_list[plt_ct][0]])\n",
    "        x_vals_shuffle = np.log(csv_vals[plt_list[plt_ct][0].replace('_avg','_shuffleavg').replace('_sum','_shufflesum')])\n",
    "        y_vals = np.log(csv_vals[plt_list[plt_ct][1]])\n",
    "        y_vals_shuffle = np.log(csv_vals[plt_list[plt_ct][1].replace('_avg','_shuffleavg').replace('_sum','_shufflesum')])\n",
    "        \n",
    "        trim_vals_x, trim_bool_x = trim_quartile(x_vals, q1_trim, q3_trim, quartile_mult)\n",
    "        trim_vals_y, trim_bool_y = trim_quartile(y_vals, q1_trim, q3_trim, quartile_mult)\n",
    "        plot_pts = (trim_bool_x) & (trim_bool_y) & (~np.isinf(x_vals) & (~np.isinf(y_vals)))\n",
    "        \n",
    "        # Set axis limits depending on the scaling of the data\n",
    "        xlv = [np.median(x_vals[plot_pts])-(2*np.std(x_vals[plot_pts])),\n",
    "               np.median(x_vals[plot_pts])+(2.5*np.std(x_vals[plot_pts]))]\n",
    "        ylv = [np.median(y_vals[plot_pts])-(2*np.std(y_vals[plot_pts])),\n",
    "               np.median(y_vals[plot_pts])+(2.5*np.std(y_vals[plot_pts]))]\n",
    "            \n",
    "        # Scatterplot the data\n",
    "        scat_im = scat_ax.scatter(x_vals[plot_pts], y_vals[plot_pts], c=np.array(color_data[plot_pts,:]), \n",
    "                                  alpha = alpha_val,\n",
    "                                  edgecolors='none',marker='o', s=np.array(size_vals[plot_pts])/size_scale)\n",
    "        scat_im.set(cmap=cmap,clim=[np.min(color_vals, axis=0),np.max(color_vals, axis=0)])\n",
    "        scat_fig.colorbar(scat_im, cax=cax, orientation='vertical')\n",
    "        scat_ax.set(xlim=xlv,ylim=ylv)\n",
    "        \n",
    "        # Generate histogram for x-axis\n",
    "        hist_vals0, hist_bins0 = np.histogram(x_vals[x_vals > 0], bins=num_hist_bins)\n",
    "        hist_vals0_shuffle, hist_bins0_shuffle = np.histogram(x_vals_shuffle[x_vals_shuffle > 0], bins=num_hist_bins)\n",
    "        \n",
    "        # Generate histogram for y-axis\n",
    "        hist_vals1, hist_bins1 = np.histogram(y_vals[y_vals > 0], bins=num_hist_bins)\n",
    "        hist_vals1_shuffle, hist_bins1_shuffle = np.histogram(y_vals_shuffle[y_vals_shuffle > 0], bins=num_hist_bins)\n",
    "    \n",
    "        # Plot histogram for x-axis\n",
    "        hist_ax0.bar(hist_bins0[1:] - (np.mean(np.diff(hist_bins0)) / 2), hist_vals0,\n",
    "                      width=(hist_bins0[-1] - hist_bins0[0]) / num_hist_bins, facecolor='silver',edgecolor='none')\n",
    "        hist_ax0.plot(hist_bins0[1:] - (np.mean(np.diff(hist_bins0)) / 2),savgol_filter(hist_vals0,smooth_len, 2),\n",
    "                      color='k',linewidth=1)\n",
    "        hist_ax0.plot(hist_bins0_shuffle[1:] - (np.mean(np.diff(hist_bins0_shuffle)) / 2),\n",
    "                      savgol_filter(hist_vals0_shuffle,smooth_len, 2),color=[0.5,0.5,1],linewidth=1,linestyle='--')\n",
    "        hist_ax0.set(xlim=scat_ax.get_xlim(),xlabel=plt_list[plt_ct][0],\n",
    "                     ylim=[np.max(np.concatenate([hist_vals0,hist_vals0_shuffle])),0])\n",
    "    \n",
    "        # Plot histogram for y-axis\n",
    "        hist_ax1.barh(hist_bins1[1:] - (np.mean(np.diff(hist_bins1)) / 2), hist_vals1,\n",
    "                      height=(hist_bins1[-1] - hist_bins1[0]) / num_hist_bins,facecolor='silver',edgecolor='none')\n",
    "        hist_ax1.plot(savgol_filter(hist_vals1,smooth_len, 2),hist_bins1[1:] - (np.mean(np.diff(hist_bins1)) / 2),\n",
    "                      color='k',linewidth=1)\n",
    "        hist_ax1.plot(savgol_filter(hist_vals1_shuffle,smooth_len, 2),\n",
    "                      hist_bins1_shuffle[1:] - (np.mean(np.diff(hist_bins1_shuffle)) / 2),\n",
    "                      color=[0.5,0.5,1],linewidth=1,linestyle='--')\n",
    "        hist_ax1.set(ylim=scat_ax.get_ylim(),ylabel=plt_list[plt_ct][1],\n",
    "                     xlim=[0,np.max(np.concatenate([hist_vals1,hist_vals1_shuffle]))])\n",
    "        hist_ax1.yaxis.set_label_position(\"right\")\n",
    "        hist_ax1.yaxis.tick_right()\n",
    "    \n",
    "        # Calculate the cutoff based on the mean and standard deviation of the shuffled ata\n",
    "        x_cut = np.mean(x_vals_shuffle[x_vals_shuffle > 0]) + 1.0 * np.std(x_vals_shuffle[x_vals_shuffle > 0])\n",
    "        y_cut = np.mean(y_vals_shuffle[y_vals_shuffle > 0]) + 1.0 * np.std(y_vals_shuffle[y_vals_shuffle > 0])\n",
    "        \n",
    "        # Add the cutoff line to the plot\n",
    "        scat_ax.plot([x_cut,x_cut],ylv,color='b',linewidth=1,linestyle='--')\n",
    "        scat_ax.plot(xlv,[y_cut,y_cut],color='b',linewidth=1,linestyle='--')\n",
    "        \n",
    "        # Set plot parameters\n",
    "        scat_ax.set(title=sum_or_avg + ' - ' + plt_list[plt_ct][0] + ' vs. ' + plt_list[plt_ct][1])\n",
    "        plt.setp(scat_ax.get_xticklabels(), visible=False)\n",
    "        plt.setp(scat_ax.get_yticklabels(), visible=False)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_plots:\n",
    "            save_fname = fdir + '/if_scatter_' + plt_list[plt_ct][0] + '_' + plt_list[plt_ct][1] + '.pdf'\n",
    "            scat_fig.savefig(save_fname)\n",
    "            plt.close(scat_fig)\n",
    "        \n",
    "        \n",
    "###############################################################################\n",
    "#             GENERATE THE UMAP PLOT BY COLOR                                 #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "if generate_umap:\n",
    "    # https://www.datacamp.com/tutorial/introduction-hierarchical-clustering-python\n",
    "    sys.stdout.write(\"\\rGenerating UMAP                                          \")\n",
    "    \n",
    "    # Generate copy of data to work on\n",
    "    clust_vals = csv_vals[umap_list].copy()\n",
    "    \n",
    "    # Log transform cluster values\n",
    "    for col_name in umap_list:\n",
    "        if col_name == 'num_pixels':\n",
    "            clust_vals[col_name] = np.sqrt(clust_vals[col_name])\n",
    "        else:\n",
    "            clust_vals[col_name] = np.log(clust_vals[col_name])\n",
    "            \n",
    "        clust_vals[col_name][clust_vals[col_name] == -np.inf] = 0\n",
    "    \n",
    "    # Trim outliers\n",
    "    for col_name in umap_list:\n",
    "        trim_vals, trim_bool = trim_quartile(clust_vals[col_name], q1_trim, q3_trim, quartile_mult)\n",
    "        clust_vals = clust_vals[trim_bool]\n",
    "        \n",
    "    # Apply Standard Scaler for unbiased clustering\n",
    "    clust_vals_scaled = StandardScaler().fit_transform(clust_vals)\n",
    "    clust_vals = pd.DataFrame(data=clust_vals_scaled,columns=list(clust_vals))\n",
    "        \n",
    "    # Generate a separate copy of the data for UMAP analysis\n",
    "    umap_vals  = clust_vals[umap_list].copy()\n",
    "        \n",
    "    # Perform clustering analysis\n",
    "    cluster_grid = sns.clustermap(data=(clust_vals),method='ward',metric='euclidean',figsize=[8,8],cmap='vlag')\n",
    "    plt_fig = plt.gcf()  # Close the figure that was generated by clustering analysis\n",
    "    plt.close(plt_fig)\n",
    "    \n",
    "    # Grab the re-ordered index values from the cluster object\n",
    "    index_list     = cluster_grid.dendrogram_row.reordered_ind\n",
    "    index_list_col = cluster_grid.dendrogram_col.reordered_ind\n",
    "    Z = cluster_grid.dendrogram_row.linkage # get the linkage matrix\n",
    "    X = cluster_grid.dendrogram_col.linkage # get the linkage matrix\n",
    "    cut_tree_val = scipy.cluster.hierarchy.cut_tree(Z) # cut the tree; leftmost: leaves (each gene is in its own cluster)\n",
    "    # rightmost: top node of tree (each gene is in the same parent cluster)\n",
    "\n",
    "    # Run Silhouette analysis to determine appropriate number of clusters\n",
    "    range_n_clusters = np.arange(2,20)\n",
    "    silhouette_avg = []\n",
    "    for n_clust in np.arange(2,20):\n",
    "        clusterer = KMeans(n_clusters=n_clust, random_state=10)\n",
    "        cluster_labels = clusterer.fit_predict(clust_vals)\n",
    "        silhouette_avg.append(silhouette_score(clust_vals, cluster_labels))\n",
    "        \n",
    "    # Generate a plot for the Silhouette analysis\n",
    "    i = num_clusts # choose what level down to cut tree\n",
    "    sil_fig = plt.figure(figsize=[6,6])\n",
    "    sil_ax = sil_fig.add_subplot(111)\n",
    "    sil_ax.bar(range_n_clusters,silhouette_avg,facecolor='none',edgecolor='k')\n",
    "    sil_ax.set(xticks=range_n_clusters,xlabel='N Clusters',ylabel='Silhouette Average Score',\n",
    "               title='Setting ' + str(i) + ' clusters')\n",
    "    \n",
    "    # Cut the cluster tree at the appropriate point for set number of clusters\n",
    "    clusters = cut_tree_val[index_list,-i]\n",
    "    \n",
    "    clusters_old = clusters.copy()\n",
    "    clusters_new = clusters.copy()\n",
    "    for clust_ind, clust_num in enumerate(clusters):\n",
    "        clusters_new[clust_ind] = clust_conj[clust_if.index(clust_num)]\n",
    "    clusters = clusters_new\n",
    "    \n",
    "    clust_vals.index = np.arange(0,len(clust_vals.index))\n",
    "    clust_vals_sort = clust_vals.copy()\n",
    "    \n",
    "    # Sort columns\n",
    "    clust_vals_sort = clust_vals_sort[np.array(list(clust_vals_sort))[index_list_col]] \n",
    "    \n",
    "    # Reorganize the spine list IDs to correspond to index values in clust_vals\n",
    "    clusters_unsorted = np.zeros(len(clust_vals_sort.index))\n",
    "    for ind_ct, ind_val in enumerate(index_list):\n",
    "        clusters_unsorted[ind_val] = clusters[ind_ct]\n",
    "        clust_vals_sort.loc[ind_ct,:] = clust_vals.loc[ind_val,:]\n",
    "        \n",
    "    # Generate a figure to show clustered data\n",
    "    clust_fig = plt.figure(figsize=[11,9])\n",
    "    gs = GridSpec(5,8,figure=clust_fig)\n",
    "    dend_ax2 = clust_fig.add_subplot(gs[0,3:8])\n",
    "    plt_ax   = clust_fig.add_subplot(gs[1:4,3:8])\n",
    "    clust_ax = clust_fig.add_subplot(gs[1:4,2])\n",
    "    dend_ax1 = clust_fig.add_subplot(gs[1:4,0:2])\n",
    "    cbar_ax  = clust_fig.add_subplot(gs[4,3:8])\n",
    "    \n",
    "    # Plot the dendrograms showing cluster heirarchies\n",
    "    hierarchy.set_link_color_palette(['silver','k'])\n",
    "    hierarchy.dendrogram(Z,ax=dend_ax1,orientation='left',color_threshold=12,#p=p,truncate_mode='level',\n",
    "                          show_leaf_counts=False,no_labels=True,above_threshold_color='k')\n",
    "    hierarchy.dendrogram(X,ax=dend_ax2,orientation='top',color_threshold=2,#p=5,truncate_mode='level',\n",
    "                          show_leaf_counts=False,no_labels=True,above_threshold_color='k')\n",
    "    dend_ax1.invert_yaxis()\n",
    "    \n",
    "    # Plot the heatmap for all cluster data\n",
    "    clust_plot = sns.heatmap(data=clust_vals_sort,ax=plt_ax,cmap='vlag',vmin=-3,vmax=3,yticklabels=[],cbar=False)\n",
    "    clust_im = clust_plot.get_children()[0]\n",
    "    sns.heatmap(data=pd.DataFrame(data=clusters),ax=clust_ax,cmap='tab10',vmin=0,vmax=9,cbar=False,\n",
    "                xticklabels=[],yticklabels=[])\n",
    "    clust_im.set(cmap='vlag',clim=[-3,3])\n",
    "    clust_fig.colorbar(clust_im, cax=cbar_ax, orientation='horizontal')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Now re-generate sorted on same column order as the conjugate dataset\n",
    "    clust_vals_sort = clust_vals_sort[np.array(['GluN1_avg','GluN2B_avg','PSD95_avg','GluA3_avg',\n",
    "                                                'num_pixels','GluA2_avg','GluA1_avg','GluA4_avg'])] \n",
    "        \n",
    "    # Generate a figure to show clustered data\n",
    "    clust_fig_sorted = plt.figure(figsize=[11,9])\n",
    "    gs = GridSpec(5,8,figure=clust_fig)\n",
    "    dend_ax2 = clust_fig_sorted.add_subplot(gs[0,3:8])\n",
    "    plt_ax   = clust_fig_sorted.add_subplot(gs[1:4,3:8])\n",
    "    clust_ax = clust_fig_sorted.add_subplot(gs[1:4,2])\n",
    "    dend_ax1 = clust_fig_sorted.add_subplot(gs[1:4,0:2])\n",
    "    cbar_ax  = clust_fig_sorted.add_subplot(gs[4,3:8])\n",
    "    \n",
    "    # Plot the dendrograms showing cluster heirarchies\n",
    "    hierarchy.set_link_color_palette(['silver','k'])\n",
    "    hierarchy.dendrogram(Z,ax=dend_ax1,orientation='left',color_threshold=12,#p=p,truncate_mode='level',\n",
    "                          show_leaf_counts=False,no_labels=True,above_threshold_color='k')\n",
    "    dend_ax1.invert_yaxis()\n",
    "    \n",
    "    # Plot the heatmap for all cluster data\n",
    "    clust_plot = sns.heatmap(data=clust_vals_sort,ax=plt_ax,cmap='vlag',vmin=-3,vmax=3,yticklabels=[],cbar=False)\n",
    "    clust_im = clust_plot.get_children()[0]\n",
    "    sns.heatmap(data=pd.DataFrame(data=clusters),ax=clust_ax,cmap='tab10',vmin=0,vmax=9,cbar=False,\n",
    "                xticklabels=[],yticklabels=[])\n",
    "    clust_im.set(cmap='vlag',clim=[-3,3])\n",
    "    clust_fig_sorted.colorbar(clust_im, cax=cbar_ax, orientation='horizontal')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Generate the UMAP reducter\n",
    "    reducer = umap.UMAP(random_state=123,n_neighbors=200, min_dist=0.25, n_components=2, metric='euclidean')\n",
    "    embedding = reducer.fit_transform(umap_vals)\n",
    "    \n",
    "    col_range = 256\n",
    "    umap_cmap = cm.binary(range(col_range))\n",
    "    \n",
    "    # Generate UMAP figure and set color scheme\n",
    "    plt_fig = plt.figure(figsize=[14,12])\n",
    "    umap_col_inds = []\n",
    "    plt_ax_list = []\n",
    "    plt_ax_list.append(plt_fig.add_subplot(3,3,1))\n",
    "    embed_cols_sortedclusts  = np.zeros([len(umap_vals),4])\n",
    "    plt_cols = cm.tab10(np.arange(0,9))\n",
    "    for spine_ct, this_spine in enumerate(clusters_unsorted):\n",
    "        embed_cols_sortedclusts[spine_ct,:] = plt_cols[int(clusters_unsorted[spine_ct]),:]\n",
    "    plt_ax_list[0].scatter(embedding[:,0],embedding[:,1],marker='o',color=embed_cols_sortedclusts,s=5,edgecolor='none')\n",
    "    plt_ax_list[0].set(title='Cluster Number')\n",
    "    plt_ax_list[0].set_aspect('equal','box')\n",
    "    # Cycle through UMAPs for each channel\n",
    "    for umap_col_ct, umap_col_name in enumerate(umap_list):\n",
    "        # Grab the column values and trim the outliers\n",
    "        col_vals = np.array(umap_vals[umap_col_name].copy())\n",
    "        col_vals_trim, trim_bool = trim_quartile(col_vals, q1_trim, q3_trim, quartile_mult)\n",
    "        # Use the trimming to set the color range for UMAPs\n",
    "        embed_col_inds = np.array((((col_vals - np.min(col_vals_trim, axis=0)[0]) / \n",
    "                                    (np.max(col_vals_trim, axis=0)[0] - np.min(col_vals_trim, axis=0)[0])) * col_range),\n",
    "                                  dtype=int)\n",
    "        embed_col_inds[embed_col_inds >= col_range] = col_range - 1\n",
    "        embed_col_inds[embed_col_inds < 0] = 0\n",
    "        # Generate the axis\n",
    "        plt_ax_list.append(plt_fig.add_subplot(3,3,umap_col_ct + 2))\n",
    "        # Plot the UMAP data and set axis properties\n",
    "        scat_im = plt_ax_list[-1].scatter(embedding[:,0],embedding[:,1],\n",
    "                                          marker='o',color=umap_cmap[embed_col_inds,:],s=5,edgecolor='none')\n",
    "        scat_im.set(cmap=cm.binary,clim=[np.min(col_vals_trim, axis=0)[0],np.max(col_vals_trim, axis=0)[0]])\n",
    "        # Make space to add a color bar to the axis\n",
    "        divider = make_axes_locatable(plt_ax_list[-1])\n",
    "        cax = divider.append_axes('bottom',size='5%',pad=0.35)\n",
    "        plt_ax_list[-1].set(title=umap_col_name)\n",
    "        plt_ax_list[-1].set_aspect('equal','box')\n",
    "        plt_fig.colorbar(scat_im, cax=cax, orientation='horizontal')\n",
    "    \n",
    "    \n",
    "    if save_plots:\n",
    "        sil_fig.savefig(fdir + '/if_silhouette.pdf')\n",
    "        plt.close(sil_fig)\n",
    "        clust_fig.savefig(fdir + '/if_synclust.pdf')\n",
    "        plt.close(clust_fig)\n",
    "        clust_fig_sorted.savefig(fdir + '/if_synclust_sort.pdf')\n",
    "        plt.close(clust_fig_sorted)\n",
    "        plt_fig.savefig(fdir + '/if_avgintens_umap.pdf')\n",
    "        plt.close(plt_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d73eba-ed04-4d0f-a302-a3ec723b1f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45fac1-3586-41a2-a7ee-90a7551b5fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d56f33-7f66-4d9a-9ef3-2c42c3f1d7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a61e21-4612-4bb9-ab35-1dd618542592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171dc4bb-c834-47fd-a07b-d5f9a609c302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
